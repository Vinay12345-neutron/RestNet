{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:23:48.575525Z","iopub.execute_input":"2025-03-17T13:23:48.575834Z","iopub.status.idle":"2025-03-17T13:23:48.870569Z","shell.execute_reply.started":"2025-03-17T13:23:48.575812Z","shell.execute_reply":"2025-03-17T13:23:48.869763Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())  # Check if GPU is available","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:23:49.509427Z","iopub.execute_input":"2025-03-17T13:23:49.509815Z","iopub.status.idle":"2025-03-17T13:23:51.083523Z","shell.execute_reply.started":"2025-03-17T13:23:49.509791Z","shell.execute_reply":"2025-03-17T13:23:51.082805Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu121\nTrue\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:23:53.145324Z","iopub.execute_input":"2025-03-17T13:23:53.145732Z","iopub.status.idle":"2025-03-17T13:23:55.392717Z","shell.execute_reply.started":"2025-03-17T13:23:53.145710Z","shell.execute_reply":"2025-03-17T13:23:55.391832Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:23:58.642299Z","iopub.execute_input":"2025-03-17T13:23:58.642838Z","iopub.status.idle":"2025-03-17T13:23:58.647527Z","shell.execute_reply.started":"2025-03-17T13:23:58.642808Z","shell.execute_reply":"2025-03-17T13:23:58.646864Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n\ntrainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\ntestloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:23:59.853768Z","iopub.execute_input":"2025-03-17T13:23:59.854046Z","iopub.status.idle":"2025-03-17T13:24:06.185631Z","shell.execute_reply.started":"2025-03-17T13:23:59.854023Z","shell.execute_reply":"2025-03-17T13:24:06.184766Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:02<00:00, 58.0MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n\nmodel = models.resnet18(weights=None, num_classes=10)  # CIFAR-10 has 10 classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:08.324808Z","iopub.execute_input":"2025-03-17T13:24:08.325143Z","iopub.status.idle":"2025-03-17T13:24:08.521354Z","shell.execute_reply.started":"2025-03-17T13:24:08.325115Z","shell.execute_reply":"2025-03-17T13:24:08.520695Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\nmodel.maxpool = nn.Identity()  # Remove the initial max pooling layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:09.552399Z","iopub.execute_input":"2025-03-17T13:24:09.552699Z","iopub.status.idle":"2025-03-17T13:24:09.557262Z","shell.execute_reply.started":"2025-03-17T13:24:09.552673Z","shell.execute_reply":"2025-03-17T13:24:09.556539Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nprint(torch.cuda.is_available())  # Should print True if GPU is available\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:11.463493Z","iopub.execute_input":"2025-03-17T13:24:11.463770Z","iopub.status.idle":"2025-03-17T13:24:11.683097Z","shell.execute_reply.started":"2025-03-17T13:24:11.463747Z","shell.execute_reply":"2025-03-17T13:24:11.682329Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:12.200358Z","iopub.execute_input":"2025-03-17T13:24:12.200590Z","iopub.status.idle":"2025-03-17T13:24:12.204097Z","shell.execute_reply.started":"2025-03-17T13:24:12.200572Z","shell.execute_reply":"2025-03-17T13:24:12.203338Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:13.134937Z","iopub.execute_input":"2025-03-17T13:24:13.135229Z","iopub.status.idle":"2025-03-17T13:24:13.139225Z","shell.execute_reply.started":"2025-03-17T13:24:13.135207Z","shell.execute_reply":"2025-03-17T13:24:13.138401Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:14.893333Z","iopub.execute_input":"2025-03-17T13:24:14.893630Z","iopub.status.idle":"2025-03-17T13:24:14.897285Z","shell.execute_reply.started":"2025-03-17T13:24:14.893606Z","shell.execute_reply":"2025-03-17T13:24:14.896458Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"num_epochs = 50\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for i, (inputs, labels) in enumerate(trainloader):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if i % 100 == 99:  # Print every 100 mini-batches\n            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], Loss: {running_loss/100:.4f}')\n            running_loss = 0.0\n\n    scheduler.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T13:24:15.317206Z","iopub.execute_input":"2025-03-17T13:24:15.317432Z","iopub.status.idle":"2025-03-17T14:03:51.249564Z","shell.execute_reply.started":"2025-03-17T13:24:15.317411Z","shell.execute_reply":"2025-03-17T14:03:51.248761Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50], Step [100/391], Loss: 2.4860\nEpoch [1/50], Step [200/391], Loss: 1.8677\nEpoch [1/50], Step [300/391], Loss: 1.7054\nEpoch [2/50], Step [100/391], Loss: 1.5000\nEpoch [2/50], Step [200/391], Loss: 1.3944\nEpoch [2/50], Step [300/391], Loss: 1.3052\nEpoch [3/50], Step [100/391], Loss: 1.1294\nEpoch [3/50], Step [200/391], Loss: 1.0371\nEpoch [3/50], Step [300/391], Loss: 0.9768\nEpoch [4/50], Step [100/391], Loss: 0.8738\nEpoch [4/50], Step [200/391], Loss: 0.8534\nEpoch [4/50], Step [300/391], Loss: 0.8016\nEpoch [5/50], Step [100/391], Loss: 0.7310\nEpoch [5/50], Step [200/391], Loss: 0.7051\nEpoch [5/50], Step [300/391], Loss: 0.6627\nEpoch [6/50], Step [100/391], Loss: 0.6179\nEpoch [6/50], Step [200/391], Loss: 0.6209\nEpoch [6/50], Step [300/391], Loss: 0.6006\nEpoch [7/50], Step [100/391], Loss: 0.5680\nEpoch [7/50], Step [200/391], Loss: 0.5613\nEpoch [7/50], Step [300/391], Loss: 0.5488\nEpoch [8/50], Step [100/391], Loss: 0.5052\nEpoch [8/50], Step [200/391], Loss: 0.5346\nEpoch [8/50], Step [300/391], Loss: 0.5228\nEpoch [9/50], Step [100/391], Loss: 0.5107\nEpoch [9/50], Step [200/391], Loss: 0.4806\nEpoch [9/50], Step [300/391], Loss: 0.5027\nEpoch [10/50], Step [100/391], Loss: 0.4872\nEpoch [10/50], Step [200/391], Loss: 0.4854\nEpoch [10/50], Step [300/391], Loss: 0.4653\nEpoch [11/50], Step [100/391], Loss: 0.4680\nEpoch [11/50], Step [200/391], Loss: 0.4689\nEpoch [11/50], Step [300/391], Loss: 0.4557\nEpoch [12/50], Step [100/391], Loss: 0.4440\nEpoch [12/50], Step [200/391], Loss: 0.4660\nEpoch [12/50], Step [300/391], Loss: 0.4458\nEpoch [13/50], Step [100/391], Loss: 0.4320\nEpoch [13/50], Step [200/391], Loss: 0.4481\nEpoch [13/50], Step [300/391], Loss: 0.4331\nEpoch [14/50], Step [100/391], Loss: 0.4163\nEpoch [14/50], Step [200/391], Loss: 0.4193\nEpoch [14/50], Step [300/391], Loss: 0.4396\nEpoch [15/50], Step [100/391], Loss: 0.4057\nEpoch [15/50], Step [200/391], Loss: 0.3996\nEpoch [15/50], Step [300/391], Loss: 0.4244\nEpoch [16/50], Step [100/391], Loss: 0.3961\nEpoch [16/50], Step [200/391], Loss: 0.4155\nEpoch [16/50], Step [300/391], Loss: 0.4078\nEpoch [17/50], Step [100/391], Loss: 0.3731\nEpoch [17/50], Step [200/391], Loss: 0.4069\nEpoch [17/50], Step [300/391], Loss: 0.3982\nEpoch [18/50], Step [100/391], Loss: 0.3792\nEpoch [18/50], Step [200/391], Loss: 0.4037\nEpoch [18/50], Step [300/391], Loss: 0.3868\nEpoch [19/50], Step [100/391], Loss: 0.3722\nEpoch [19/50], Step [200/391], Loss: 0.4001\nEpoch [19/50], Step [300/391], Loss: 0.4000\nEpoch [20/50], Step [100/391], Loss: 0.3698\nEpoch [20/50], Step [200/391], Loss: 0.3791\nEpoch [20/50], Step [300/391], Loss: 0.3798\nEpoch [21/50], Step [100/391], Loss: 0.3775\nEpoch [21/50], Step [200/391], Loss: 0.3703\nEpoch [21/50], Step [300/391], Loss: 0.3750\nEpoch [22/50], Step [100/391], Loss: 0.3621\nEpoch [22/50], Step [200/391], Loss: 0.3858\nEpoch [22/50], Step [300/391], Loss: 0.3836\nEpoch [23/50], Step [100/391], Loss: 0.3731\nEpoch [23/50], Step [200/391], Loss: 0.3572\nEpoch [23/50], Step [300/391], Loss: 0.3706\nEpoch [24/50], Step [100/391], Loss: 0.3426\nEpoch [24/50], Step [200/391], Loss: 0.3694\nEpoch [24/50], Step [300/391], Loss: 0.3794\nEpoch [25/50], Step [100/391], Loss: 0.3407\nEpoch [25/50], Step [200/391], Loss: 0.3696\nEpoch [25/50], Step [300/391], Loss: 0.3766\nEpoch [26/50], Step [100/391], Loss: 0.3396\nEpoch [26/50], Step [200/391], Loss: 0.3539\nEpoch [26/50], Step [300/391], Loss: 0.3781\nEpoch [27/50], Step [100/391], Loss: 0.3556\nEpoch [27/50], Step [200/391], Loss: 0.3612\nEpoch [27/50], Step [300/391], Loss: 0.3665\nEpoch [28/50], Step [100/391], Loss: 0.3454\nEpoch [28/50], Step [200/391], Loss: 0.3710\nEpoch [28/50], Step [300/391], Loss: 0.3642\nEpoch [29/50], Step [100/391], Loss: 0.3373\nEpoch [29/50], Step [200/391], Loss: 0.3584\nEpoch [29/50], Step [300/391], Loss: 0.3488\nEpoch [30/50], Step [100/391], Loss: 0.3456\nEpoch [30/50], Step [200/391], Loss: 0.3498\nEpoch [30/50], Step [300/391], Loss: 0.3639\nEpoch [31/50], Step [100/391], Loss: 0.2537\nEpoch [31/50], Step [200/391], Loss: 0.1891\nEpoch [31/50], Step [300/391], Loss: 0.1823\nEpoch [32/50], Step [100/391], Loss: 0.1561\nEpoch [32/50], Step [200/391], Loss: 0.1512\nEpoch [32/50], Step [300/391], Loss: 0.1482\nEpoch [33/50], Step [100/391], Loss: 0.1247\nEpoch [33/50], Step [200/391], Loss: 0.1262\nEpoch [33/50], Step [300/391], Loss: 0.1325\nEpoch [34/50], Step [100/391], Loss: 0.1194\nEpoch [34/50], Step [200/391], Loss: 0.1139\nEpoch [34/50], Step [300/391], Loss: 0.1131\nEpoch [35/50], Step [100/391], Loss: 0.1001\nEpoch [35/50], Step [200/391], Loss: 0.0984\nEpoch [35/50], Step [300/391], Loss: 0.1087\nEpoch [36/50], Step [100/391], Loss: 0.0926\nEpoch [36/50], Step [200/391], Loss: 0.0912\nEpoch [36/50], Step [300/391], Loss: 0.0969\nEpoch [37/50], Step [100/391], Loss: 0.0852\nEpoch [37/50], Step [200/391], Loss: 0.0852\nEpoch [37/50], Step [300/391], Loss: 0.0873\nEpoch [38/50], Step [100/391], Loss: 0.0772\nEpoch [38/50], Step [200/391], Loss: 0.0734\nEpoch [38/50], Step [300/391], Loss: 0.0760\nEpoch [39/50], Step [100/391], Loss: 0.0735\nEpoch [39/50], Step [200/391], Loss: 0.0731\nEpoch [39/50], Step [300/391], Loss: 0.0661\nEpoch [40/50], Step [100/391], Loss: 0.0666\nEpoch [40/50], Step [200/391], Loss: 0.0669\nEpoch [40/50], Step [300/391], Loss: 0.0680\nEpoch [41/50], Step [100/391], Loss: 0.0578\nEpoch [41/50], Step [200/391], Loss: 0.0613\nEpoch [41/50], Step [300/391], Loss: 0.0639\nEpoch [42/50], Step [100/391], Loss: 0.0523\nEpoch [42/50], Step [200/391], Loss: 0.0582\nEpoch [42/50], Step [300/391], Loss: 0.0563\nEpoch [43/50], Step [100/391], Loss: 0.0486\nEpoch [43/50], Step [200/391], Loss: 0.0525\nEpoch [43/50], Step [300/391], Loss: 0.0616\nEpoch [44/50], Step [100/391], Loss: 0.0467\nEpoch [44/50], Step [200/391], Loss: 0.0474\nEpoch [44/50], Step [300/391], Loss: 0.0530\nEpoch [45/50], Step [100/391], Loss: 0.0472\nEpoch [45/50], Step [200/391], Loss: 0.0486\nEpoch [45/50], Step [300/391], Loss: 0.0557\nEpoch [46/50], Step [100/391], Loss: 0.0462\nEpoch [46/50], Step [200/391], Loss: 0.0487\nEpoch [46/50], Step [300/391], Loss: 0.0467\nEpoch [47/50], Step [100/391], Loss: 0.0387\nEpoch [47/50], Step [200/391], Loss: 0.0417\nEpoch [47/50], Step [300/391], Loss: 0.0459\nEpoch [48/50], Step [100/391], Loss: 0.0444\nEpoch [48/50], Step [200/391], Loss: 0.0433\nEpoch [48/50], Step [300/391], Loss: 0.0550\nEpoch [49/50], Step [100/391], Loss: 0.0470\nEpoch [49/50], Step [200/391], Loss: 0.0480\nEpoch [49/50], Step [300/391], Loss: 0.0435\nEpoch [50/50], Step [100/391], Loss: 0.0416\nEpoch [50/50], Step [200/391], Loss: 0.0502\nEpoch [50/50], Step [300/391], Loss: 0.0490\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"torch.save(model.state_dict(), 'resnet18_cifar10.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T14:05:52.220174Z","iopub.execute_input":"2025-03-17T14:05:52.220510Z","iopub.status.idle":"2025-03-17T14:05:52.299738Z","shell.execute_reply.started":"2025-03-17T14:05:52.220486Z","shell.execute_reply":"2025-03-17T14:05:52.299084Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for inputs, labels in testloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy on test set: {100 * correct / total:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T14:05:57.038569Z","iopub.execute_input":"2025-03-17T14:05:57.038888Z","iopub.status.idle":"2025-03-17T14:06:00.143369Z","shell.execute_reply.started":"2025-03-17T14:05:57.038865Z","shell.execute_reply":"2025-03-17T14:06:00.142351Z"}},"outputs":[{"name":"stdout","text":"Accuracy on test set: 93.35%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}